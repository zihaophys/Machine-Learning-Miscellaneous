{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = datasets.FashionMNIST(root='.', train=True, download=True, transform=ToTensor())\n",
    "test_data = datasets.FashionMNIST(root='.', train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
       "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
       "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
       "           0.0157, 0.0000, 0.0000, 0.0118],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
       "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0471, 0.0392, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
       "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
       "           0.3020, 0.5098, 0.2824, 0.0588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
       "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
       "           0.5529, 0.3451, 0.6745, 0.2588],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
       "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
       "           0.4824, 0.7686, 0.8980, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
       "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
       "           0.8745, 0.9608, 0.6784, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
       "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
       "           0.8627, 0.9529, 0.7922, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
       "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
       "           0.8863, 0.7725, 0.8196, 0.2039],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
       "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
       "           0.9608, 0.4667, 0.6549, 0.2196],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
       "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
       "           0.8510, 0.8196, 0.3608, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
       "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
       "           0.8549, 1.0000, 0.3020, 0.0000],\n",
       "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
       "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
       "           0.8784, 0.9569, 0.6235, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
       "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
       "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
       "           0.9137, 0.9333, 0.8431, 0.0000],\n",
       "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
       "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
       "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
       "           0.8627, 0.9098, 0.9647, 0.0000],\n",
       "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
       "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
       "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
       "           0.8706, 0.8941, 0.8824, 0.0000],\n",
       "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
       "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
       "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
       "           0.8745, 0.8784, 0.8980, 0.1137],\n",
       "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
       "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
       "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
       "           0.8627, 0.8667, 0.9020, 0.2627],\n",
       "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
       "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
       "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
       "           0.7098, 0.8039, 0.8078, 0.4510],\n",
       "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
       "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
       "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
       "           0.6549, 0.6941, 0.8235, 0.3608],\n",
       "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
       "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
       "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
       "           0.7529, 0.8471, 0.6667, 0.0000],\n",
       "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
       "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
       "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
       "           0.3882, 0.2275, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
       "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
       " 9)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {\n",
    "    0: \"T-Shirt\",\n",
    "    1: \"Trouser\",\n",
    "    2: \"Pullover\",\n",
    "    3: \"Dress\",\n",
    "    4: \"Coat\",\n",
    "    5: \"Sandal\",\n",
    "    6: \"Shirt\",\n",
    "    7: \"Sneaker\",\n",
    "    8: \"Bag\",\n",
    "    9: \"Ankle Boot\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(3, 3, figsize=(8,8))\n",
    "cols, rows = 3, 3\n",
    "for col in range(cols):\n",
    "    for row in range(rows):\n",
    "        sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
    "        img, label = training_data[sample_idx]\n",
    "        ax[col][row].set_title(f'{labels_map[label]}')\n",
    "        ax[col][row].imshow(img.squeeze(), cmap='gray')\n",
    "        ax[col][row].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torchvision.io as tvio\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = pd.read_csv(annotations_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = tvio.read_image(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        sample = {'image': image, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "training_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28]) torch.Size([64])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_features, train_labels = next(iter(training_dataloader))\n",
    "print(train_features.size(), train_labels.size())\n",
    "img = train_features[0].squeeze()\n",
    "label = train_labels[0]\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.title(labels_map[label.item()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 3, 5, 2, 0, 3, 0, 7, 3, 2, 2, 3, 8, 0, 1, 6, 4, 2, 4, 0, 6, 7, 6, 9,\n",
       "        1, 1, 5, 5, 2, 3, 6, 7, 8, 5, 8, 7, 0, 5, 6, 5, 9, 8, 1, 0, 3, 8, 1, 1,\n",
       "        3, 1, 5, 7, 6, 3, 1, 0, 9, 8, 8, 9, 5, 8, 9, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = datasets.FashionMNIST(\n",
    "    root='.',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=Lambda(lambda y: torch.zeros(10, dtype=torch.float).scatter_(0, torch.tensor(y), value=1))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.line_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.line_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (line_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to('cpu')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([9])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28)\n",
    "logits = model(X)\n",
    "pred_probab = nn.Softmax(dim=1)(logits)\n",
    "y_pred = pred_probab.argmax(1)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Softmax(\n",
       "  dim=tensor([[0.0265, 0.0509, 0.0348, 0.0322, 0.0000, 0.0675, 0.0122, 0.0000, 0.0830,\n",
       "           0.1323],\n",
       "          [0.0000, 0.0000, 0.0887, 0.0347, 0.0000, 0.0116, 0.0000, 0.0000, 0.0950,\n",
       "           0.0967],\n",
       "          [0.0000, 0.0188, 0.0545, 0.0000, 0.0000, 0.0412, 0.0274, 0.0000, 0.1186,\n",
       "           0.1294]], grad_fn=<ReluBackward0>)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Softmax(model(input_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    }
   ],
   "source": [
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU: tensor([[ 0.0975, -0.4646,  0.8462, -0.0069, -0.3134, -0.2323,  0.0871, -0.0360,\n",
      "          0.1074, -0.5857,  0.1789, -0.4663, -0.3879, -0.6277, -0.1654,  0.4049,\n",
      "         -0.0798,  0.1764, -0.1328,  0.0728],\n",
      "        [ 0.1507, -0.1780,  0.7024,  0.0518,  0.0339,  0.1202, -0.1751, -0.3060,\n",
      "          0.2260, -0.3171, -0.2287, -0.3181, -0.3682, -0.6227, -0.0925,  0.7629,\n",
      "         -0.4109,  0.1618,  0.0802,  0.2609],\n",
      "        [ 0.1692, -0.6434,  0.4929,  0.1156,  0.1868, -0.0598,  0.0068, -0.1408,\n",
      "          0.2723, -0.3340, -0.4527, -0.2687, -0.2330, -0.6454, -0.1590,  0.6010,\n",
      "          0.0899,  0.1846,  0.0175,  0.2703]], grad_fn=<AddmmBackward>)\n",
      "\n",
      "\n",
      "After ReLU: tensor([[0.0975, 0.0000, 0.8462, 0.0000, 0.0000, 0.0000, 0.0871, 0.0000, 0.1074,\n",
      "         0.0000, 0.1789, 0.0000, 0.0000, 0.0000, 0.0000, 0.4049, 0.0000, 0.1764,\n",
      "         0.0000, 0.0728],\n",
      "        [0.1507, 0.0000, 0.7024, 0.0518, 0.0339, 0.1202, 0.0000, 0.0000, 0.2260,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7629, 0.0000, 0.1618,\n",
      "         0.0802, 0.2609],\n",
      "        [0.1692, 0.0000, 0.4929, 0.1156, 0.1868, 0.0000, 0.0068, 0.0000, 0.2723,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6010, 0.0899, 0.1846,\n",
      "         0.0175, 0.2703]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"After ReLU: {hidden1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3,28,28)\n",
    "logits = seq_modules(input_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_probab = softmax(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1217, 0.1230, 0.0770, 0.0914, 0.1327, 0.0812, 0.0721, 0.0997, 0.0735,\n",
       "         0.1276],\n",
       "        [0.0990, 0.1320, 0.0886, 0.0974, 0.1275, 0.0721, 0.0765, 0.0919, 0.0706,\n",
       "         0.1443],\n",
       "        [0.1140, 0.1261, 0.0912, 0.0845, 0.1257, 0.0804, 0.0884, 0.0922, 0.0788,\n",
       "         0.1187]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:  NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (line_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "    (5): ReLU()\n",
      "  )\n",
      ") \n",
      "\n",
      "\n",
      "Layer: line_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0030, -0.0014, -0.0338,  ..., -0.0317,  0.0328,  0.0008],\n",
      "        [ 0.0017, -0.0186,  0.0080,  ...,  0.0103,  0.0021, -0.0264]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: line_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0073,  0.0020], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: line_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0258, -0.0167, -0.0431,  ...,  0.0419, -0.0111, -0.0097],\n",
      "        [ 0.0206,  0.0069, -0.0058,  ...,  0.0007, -0.0121, -0.0032]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: line_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0156,  0.0128], grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: line_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 0.0354,  0.0051,  0.0279,  ..., -0.0012,  0.0432, -0.0202],\n",
      "        [ 0.0365, -0.0044, -0.0097,  ...,  0.0325, -0.0363, -0.0345]],\n",
      "       grad_fn=<SliceBackward>) \n",
      "\n",
      "Layer: line_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([0.0023, 0.0436], grad_fn=<SliceBackward>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model structure: \", model, \"\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: .\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: .\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x1302df610>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x12b9316d0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (line_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<enumerate at 0x1354f95a0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enumerate(training_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):        \n",
    "        # Compute prediction and loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print(batch,' ', len(X))\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            \n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.301379  [    0/60000]\n",
      "loss: 1.250721  [ 6400/60000]\n",
      "loss: 1.039586  [12800/60000]\n",
      "loss: 1.199550  [19200/60000]\n",
      "loss: 1.271846  [25600/60000]\n",
      "loss: 1.146938  [32000/60000]\n",
      "loss: 1.075728  [38400/60000]\n",
      "loss: 1.340090  [44800/60000]\n",
      "loss: 1.191586  [51200/60000]\n",
      "loss: 1.247761  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.3%, Avg loss: 0.018750 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.097659  [    0/60000]\n",
      "loss: 1.147642  [ 6400/60000]\n",
      "loss: 1.107060  [12800/60000]\n",
      "loss: 1.351408  [19200/60000]\n",
      "loss: 1.222163  [25600/60000]\n",
      "loss: 1.135472  [32000/60000]\n",
      "loss: 1.487863  [38400/60000]\n",
      "loss: 1.031504  [44800/60000]\n",
      "loss: 1.077806  [51200/60000]\n",
      "loss: 1.313666  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 58.8%, Avg loss: 0.018415 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.154952  [    0/60000]\n",
      "loss: 1.192277  [ 6400/60000]\n",
      "loss: 1.155669  [12800/60000]\n",
      "loss: 1.327396  [19200/60000]\n",
      "loss: 0.984707  [25600/60000]\n",
      "loss: 1.196249  [32000/60000]\n",
      "loss: 1.214896  [38400/60000]\n",
      "loss: 1.186963  [44800/60000]\n",
      "loss: 1.265690  [51200/60000]\n",
      "loss: 0.979755  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 59.6%, Avg loss: 0.018131 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.198837  [    0/60000]\n",
      "loss: 1.099577  [ 6400/60000]\n",
      "loss: 1.001835  [12800/60000]\n",
      "loss: 1.081666  [19200/60000]\n",
      "loss: 1.298774  [25600/60000]\n",
      "loss: 1.009210  [32000/60000]\n",
      "loss: 1.081693  [38400/60000]\n",
      "loss: 1.134080  [44800/60000]\n",
      "loss: 1.135900  [51200/60000]\n",
      "loss: 1.083159  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.6%, Avg loss: 0.017840 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.252400  [    0/60000]\n",
      "loss: 1.210404  [ 6400/60000]\n",
      "loss: 0.925973  [12800/60000]\n",
      "loss: 1.208707  [19200/60000]\n",
      "loss: 0.952580  [25600/60000]\n",
      "loss: 1.212126  [32000/60000]\n",
      "loss: 1.173065  [38400/60000]\n",
      "loss: 0.947869  [44800/60000]\n",
      "loss: 1.049105  [51200/60000]\n",
      "loss: 1.167843  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 60.9%, Avg loss: 0.017569 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(training_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x1355ad4d0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('line_relu_stack.0.weight',\n",
       "              tensor([[ 0.0030, -0.0014, -0.0338,  ..., -0.0313,  0.0328,  0.0008],\n",
       "                      [ 0.0017, -0.0186,  0.0079,  ...,  0.0098,  0.0020, -0.0264],\n",
       "                      [-0.0053, -0.0242,  0.0207,  ..., -0.0166,  0.0150, -0.0191],\n",
       "                      ...,\n",
       "                      [-0.0218, -0.0194, -0.0045,  ..., -0.0097,  0.0056, -0.0156],\n",
       "                      [-0.0128,  0.0080,  0.0261,  ..., -0.0010,  0.0305,  0.0144],\n",
       "                      [-0.0333,  0.0053,  0.0008,  ...,  0.0072, -0.0288,  0.0043]])),\n",
       "             ('line_relu_stack.0.bias',\n",
       "              tensor([-8.8711e-03,  9.4875e-03, -5.7390e-03,  1.6919e-02, -7.1484e-03,\n",
       "                      -2.5169e-02, -2.1012e-02, -2.2411e-02,  6.3563e-04,  2.9594e-02,\n",
       "                      -1.3037e-02,  5.3384e-02, -3.9386e-03, -8.5686e-03, -3.5057e-02,\n",
       "                      -1.0690e-02,  3.0353e-02,  1.8828e-02,  8.3908e-03, -1.9589e-02,\n",
       "                       3.4404e-02,  4.6967e-02, -2.3085e-02,  4.1950e-02, -2.3505e-02,\n",
       "                      -3.2699e-02,  1.2171e-02, -7.5399e-03, -4.6136e-05,  2.6689e-02,\n",
       "                      -2.2867e-03,  3.0352e-02, -1.2804e-02,  1.8194e-02,  3.3256e-03,\n",
       "                       2.3180e-02,  1.7895e-02, -2.8542e-02,  8.2145e-03, -1.0944e-02,\n",
       "                       3.2752e-02, -3.3805e-02, -2.1633e-02, -3.0121e-02,  5.2392e-02,\n",
       "                      -8.5358e-03,  2.7849e-02,  2.3348e-02, -1.2417e-02,  9.7100e-03,\n",
       "                      -1.6831e-02,  3.7461e-02,  1.4282e-02,  4.6308e-02,  3.4456e-02,\n",
       "                       9.0374e-03,  5.3830e-02,  6.8170e-03, -3.1184e-02,  6.8047e-03,\n",
       "                      -2.2583e-04, -1.7576e-02,  2.2449e-02, -1.1987e-02,  3.0504e-02,\n",
       "                       2.9392e-02,  1.5640e-02, -2.9648e-02, -4.8364e-03, -1.2808e-03,\n",
       "                       2.3384e-02,  3.1353e-02,  2.5958e-02,  3.1666e-02,  2.4562e-03,\n",
       "                       1.0780e-03, -1.1485e-02,  2.4560e-02, -9.6978e-03,  2.3432e-02,\n",
       "                       1.9317e-02,  2.6475e-02, -2.5050e-02,  4.2578e-02, -1.6533e-03,\n",
       "                      -2.9182e-03, -4.2498e-03, -1.6015e-02, -1.8990e-02,  5.0194e-02,\n",
       "                      -2.0929e-02,  2.9962e-02,  1.6592e-02, -1.6999e-02, -5.8448e-03,\n",
       "                      -2.1302e-02,  1.9149e-02, -6.1346e-03,  2.8114e-02,  2.0875e-02,\n",
       "                      -1.2935e-02,  1.9233e-02, -3.0064e-03, -2.9283e-02,  1.9222e-02,\n",
       "                      -1.7105e-02,  1.2271e-02,  1.2603e-02, -3.9493e-02,  2.8805e-02,\n",
       "                      -1.5177e-02,  3.6108e-02,  2.3157e-02,  3.8044e-02,  3.3493e-02,\n",
       "                      -5.0754e-03, -2.4903e-02,  2.6660e-02, -2.7926e-02,  5.1374e-04,\n",
       "                      -2.9464e-02,  3.5425e-02, -3.0373e-02, -2.5593e-02, -4.7717e-04,\n",
       "                      -7.7171e-03, -1.4697e-02,  6.4135e-03,  1.7885e-02,  9.3239e-03,\n",
       "                      -2.6682e-02, -1.7024e-02, -2.0244e-02,  2.4604e-03,  3.5383e-02,\n",
       "                       4.2265e-02,  1.5036e-02, -1.9393e-03, -2.2356e-02,  3.2998e-02,\n",
       "                       4.1914e-03, -7.9701e-03,  2.9072e-02, -3.5951e-02,  2.8511e-02,\n",
       "                       4.5236e-02, -3.3677e-02,  2.8421e-02,  1.9427e-02,  3.4169e-02,\n",
       "                       1.1176e-02,  2.2281e-02, -2.3556e-02, -8.4340e-03, -2.0054e-02,\n",
       "                       3.7809e-02, -7.7664e-03, -1.9449e-02,  3.9716e-02, -3.5382e-02,\n",
       "                      -3.5231e-03,  1.5045e-03,  2.0776e-02, -1.9655e-02, -2.5685e-02,\n",
       "                       1.7615e-02,  2.6654e-02,  4.1046e-02, -2.1800e-02, -3.0514e-03,\n",
       "                       2.4785e-02, -1.1975e-02,  4.3783e-02,  7.6617e-03, -3.0488e-02,\n",
       "                      -1.2376e-02,  1.7290e-03,  1.9775e-02, -8.5154e-04,  8.9103e-03,\n",
       "                      -2.1887e-02, -3.2648e-02,  3.1632e-02,  3.2761e-02, -2.3306e-02,\n",
       "                       2.8280e-02, -7.3873e-03,  2.8673e-02,  9.4057e-03,  3.0061e-03,\n",
       "                      -2.0831e-02,  2.2028e-02,  2.4240e-02,  2.4624e-02,  2.5051e-02,\n",
       "                       2.9412e-02,  4.8458e-04, -1.5325e-02,  2.5907e-02, -1.9724e-02,\n",
       "                       1.2272e-02,  2.4738e-02, -8.9891e-03,  5.8645e-03, -9.7662e-03,\n",
       "                       1.5821e-02,  1.1110e-02, -1.5479e-02, -2.1894e-02,  3.1883e-02,\n",
       "                      -8.7612e-03,  3.7060e-02,  2.8780e-02, -2.1772e-02, -2.1820e-02,\n",
       "                      -9.9110e-03,  1.8120e-02,  1.3906e-02, -1.3996e-02, -2.3011e-02,\n",
       "                      -2.6056e-02, -2.9778e-02,  2.4701e-02,  2.4497e-02,  8.5320e-03,\n",
       "                       1.7213e-02,  7.7136e-03, -2.0217e-02, -2.6118e-02,  3.9531e-02,\n",
       "                      -8.0876e-03,  3.3251e-02, -7.1139e-03, -2.7720e-03,  1.5029e-02,\n",
       "                       1.8450e-02, -1.6675e-02,  4.1458e-02,  5.4166e-02, -2.9253e-02,\n",
       "                       1.6008e-02,  4.1473e-03,  8.5035e-03, -4.5178e-03,  2.7349e-02,\n",
       "                       3.7820e-02,  2.2759e-02,  2.8361e-02,  2.9406e-02,  9.8140e-03,\n",
       "                       1.6302e-02,  2.7909e-02,  4.0711e-02,  3.9745e-03,  1.0282e-02,\n",
       "                       4.4889e-03, -2.7787e-02, -3.4756e-02, -2.9826e-02,  2.4486e-02,\n",
       "                      -1.4231e-03, -2.2751e-02, -2.1748e-02, -1.8896e-02, -1.6565e-02,\n",
       "                      -2.4338e-02,  2.8881e-02,  3.4523e-02, -1.8880e-02,  1.7028e-02,\n",
       "                      -1.3646e-02,  5.2570e-03,  1.5941e-02,  2.6466e-03,  3.1764e-03,\n",
       "                      -1.6991e-02,  2.3082e-02, -1.1506e-02, -9.9665e-03, -3.5902e-02,\n",
       "                       1.8396e-02,  3.8352e-02, -1.3459e-02,  2.2714e-02,  3.4117e-02,\n",
       "                       3.9812e-02, -3.6957e-02, -4.9269e-02, -2.5710e-02, -4.6052e-03,\n",
       "                       4.0798e-02, -2.6784e-02, -1.9075e-03, -1.4216e-02,  2.7647e-02,\n",
       "                       3.4655e-02, -1.9907e-02,  2.9255e-02,  3.3211e-02, -5.8391e-03,\n",
       "                       1.4961e-02, -2.5046e-02,  1.4711e-02,  3.4413e-02,  7.1490e-03,\n",
       "                       4.5078e-02, -5.9865e-03,  2.4171e-02, -1.4081e-02, -9.5402e-03,\n",
       "                       3.3975e-02,  3.2081e-02,  1.6886e-02, -8.0670e-03,  3.8681e-03,\n",
       "                      -2.0470e-02,  2.9544e-02, -2.4771e-02,  2.8499e-03,  1.3248e-03,\n",
       "                      -1.2216e-02,  4.6033e-03, -1.5941e-02, -6.9878e-03, -1.3814e-02,\n",
       "                       2.1678e-02,  1.8163e-02, -4.2011e-02, -4.1702e-03, -4.1176e-03,\n",
       "                       3.3759e-02,  2.9703e-02, -1.1060e-02, -1.0781e-02, -2.1162e-02,\n",
       "                       2.6942e-02,  3.4649e-02,  1.5071e-02, -8.6497e-03,  5.0557e-03,\n",
       "                       1.7533e-02,  5.7014e-03, -6.4543e-03, -2.0872e-02,  3.4892e-02,\n",
       "                      -2.0999e-02,  7.2379e-04,  1.9276e-02, -1.3533e-02,  4.1311e-02,\n",
       "                       3.2414e-02,  8.6060e-05,  4.5749e-02,  2.1721e-02,  3.0873e-02,\n",
       "                      -3.9106e-02, -3.2230e-03,  1.7766e-02,  1.6074e-02, -1.9635e-02,\n",
       "                       1.1238e-02,  8.3973e-03,  8.9029e-03,  3.6642e-02,  1.8318e-02,\n",
       "                      -1.2766e-02, -9.8474e-03, -2.8380e-03,  3.0451e-02,  1.3469e-02,\n",
       "                      -1.8488e-02, -2.7204e-02,  2.8456e-02, -2.1600e-02,  3.7589e-02,\n",
       "                      -2.0104e-02,  3.4892e-02, -2.3770e-02,  1.1127e-02,  2.9240e-02,\n",
       "                       1.2923e-02,  4.2245e-02,  3.4603e-02,  3.6477e-02,  1.6353e-04,\n",
       "                      -3.7207e-02, -1.0684e-02, -2.8880e-02, -2.7365e-03,  3.2378e-02,\n",
       "                       1.5738e-02,  2.5578e-02,  2.9147e-02,  1.7155e-02,  1.2753e-03,\n",
       "                       9.1432e-03, -3.2438e-03,  5.4210e-02, -1.8644e-02,  1.8499e-02,\n",
       "                       4.3465e-02,  1.2048e-02, -1.9031e-02,  5.0833e-03,  2.2059e-02,\n",
       "                       3.2800e-03,  2.0589e-02,  2.9541e-02, -1.1075e-03,  1.1733e-02,\n",
       "                      -3.6928e-02,  3.3062e-02, -2.0529e-02,  8.2722e-03,  5.6577e-03,\n",
       "                      -1.4913e-02,  2.1233e-02, -2.7359e-02,  4.2933e-04,  4.8862e-02,\n",
       "                       2.7103e-02,  6.6523e-03, -8.5982e-03,  1.7469e-02, -1.3010e-02,\n",
       "                      -3.2900e-02, -7.2124e-03,  1.1760e-02,  4.5054e-03, -1.8004e-02,\n",
       "                       7.8251e-04,  2.2926e-02, -7.5671e-03, -1.6658e-02, -2.2712e-02,\n",
       "                       1.0495e-02, -2.7640e-02,  2.5728e-02, -1.8483e-03, -8.7401e-04,\n",
       "                       1.5375e-02,  8.6741e-04,  2.3334e-02, -9.3503e-03,  3.5524e-02,\n",
       "                       3.3749e-02,  2.4093e-02, -1.6908e-02, -1.5937e-02,  4.9560e-02,\n",
       "                       2.9123e-02,  3.4808e-02,  3.9672e-02, -2.1291e-02,  1.4858e-02,\n",
       "                       2.8373e-02, -2.3942e-02,  7.7574e-03,  2.9639e-02,  1.6580e-02,\n",
       "                       5.9314e-03,  1.5368e-02,  9.1012e-03,  3.1163e-02, -1.0259e-02,\n",
       "                       4.1041e-02,  1.0946e-02, -1.0888e-02, -2.0485e-03,  1.5410e-02,\n",
       "                      -2.6187e-02, -4.8702e-03,  4.3534e-03,  1.9766e-02,  4.6464e-02,\n",
       "                      -2.0798e-02, -9.0038e-03,  3.4106e-02,  2.2028e-02,  5.2758e-02,\n",
       "                       2.1833e-02,  1.7153e-02, -2.7840e-02, -2.3655e-02,  4.7855e-02,\n",
       "                      -2.4472e-02, -3.3932e-02,  3.1743e-02, -2.9828e-02,  5.7187e-03,\n",
       "                       3.3394e-02, -2.4656e-02,  1.9121e-02, -4.0615e-03,  2.4137e-02,\n",
       "                       6.3057e-03,  1.3030e-02,  3.5073e-03,  3.3724e-02,  6.4232e-02,\n",
       "                       9.5500e-03, -1.2659e-02,  3.7970e-02, -1.1910e-02, -1.5201e-02,\n",
       "                      -2.6273e-02,  8.0952e-03, -3.8387e-02,  1.9858e-02, -2.6518e-02,\n",
       "                      -6.3017e-03,  2.4313e-02])),\n",
       "             ('line_relu_stack.2.weight',\n",
       "              tensor([[-0.0318, -0.0092, -0.0419,  ...,  0.0418, -0.0111, -0.0099],\n",
       "                      [ 0.0177,  0.0082, -0.0062,  ...,  0.0007, -0.0121, -0.0033],\n",
       "                      [-0.0166, -0.0237,  0.0371,  ..., -0.0306, -0.0358, -0.0369],\n",
       "                      ...,\n",
       "                      [ 0.0269,  0.0336,  0.0436,  ...,  0.0129,  0.0044,  0.0313],\n",
       "                      [-0.0342, -0.0436,  0.0067,  ...,  0.0044,  0.0287,  0.0281],\n",
       "                      [-0.0122, -0.0385,  0.0356,  ..., -0.0073, -0.0391, -0.0090]])),\n",
       "             ('line_relu_stack.2.bias',\n",
       "              tensor([-1.8681e-02,  1.0940e-02, -5.8432e-04,  8.9088e-03, -1.7361e-03,\n",
       "                       1.2793e-02,  1.0690e-03,  3.2614e-02,  6.5284e-02,  2.5303e-02,\n",
       "                       3.8430e-02, -2.5667e-02,  1.8078e-02,  1.9169e-02, -6.5631e-03,\n",
       "                       3.5475e-02,  2.9370e-02, -3.8567e-02, -2.7729e-03,  4.2268e-02,\n",
       "                       2.3873e-02, -2.9655e-02,  4.9297e-02,  1.5113e-02, -2.6903e-02,\n",
       "                       5.8952e-02,  2.1194e-02,  3.3144e-02,  2.3050e-02, -3.9119e-02,\n",
       "                      -1.8360e-02,  2.4266e-02, -2.3683e-03, -2.3910e-02, -1.2881e-03,\n",
       "                      -2.9410e-02, -3.0679e-02,  3.2947e-02,  2.1175e-04,  2.8487e-02,\n",
       "                      -4.8830e-03,  4.4450e-02,  2.5320e-02,  1.2214e-02, -2.6934e-02,\n",
       "                       2.5855e-04, -3.6866e-02,  2.8225e-02,  7.5392e-03, -1.1280e-02,\n",
       "                      -3.0524e-03,  2.1021e-02, -5.2988e-04, -4.3132e-02,  4.0222e-03,\n",
       "                      -1.3314e-02,  4.8755e-02, -3.8621e-02,  2.7850e-02, -2.0941e-02,\n",
       "                      -2.1105e-02, -2.1234e-02,  1.4103e-02,  1.3485e-02, -3.0727e-02,\n",
       "                       3.2589e-03, -3.1886e-05,  1.3101e-02,  3.6896e-02, -7.0977e-03,\n",
       "                       2.2143e-02,  3.0572e-03, -6.2960e-03, -3.8108e-02,  1.0346e-02,\n",
       "                      -1.6125e-02,  5.6375e-02, -1.9626e-02,  7.4576e-03,  1.6501e-02,\n",
       "                       7.0877e-04,  4.8485e-02, -4.2643e-02, -1.5522e-02,  2.4660e-02,\n",
       "                      -3.0963e-02,  4.2564e-02,  8.7329e-03, -6.0411e-02, -2.2706e-03,\n",
       "                       2.5843e-02,  2.1678e-02, -3.2064e-02,  2.4853e-02, -3.5726e-03,\n",
       "                      -2.6749e-02,  3.2283e-02,  5.0685e-02,  2.3628e-02,  2.7607e-02,\n",
       "                      -1.7349e-03, -9.7434e-03,  3.8505e-02,  5.9536e-02,  3.7113e-02,\n",
       "                      -9.6313e-03, -4.2122e-02, -1.6788e-02,  3.3831e-02, -2.8061e-02,\n",
       "                      -2.6613e-02, -2.6276e-02, -1.4435e-02, -3.3432e-02, -3.8628e-03,\n",
       "                       4.6632e-02,  2.5846e-02, -2.2668e-02,  6.3054e-02, -1.0879e-02,\n",
       "                      -7.9620e-03,  2.8252e-02,  6.9903e-04, -1.8922e-02,  2.3501e-02,\n",
       "                       3.3908e-02,  1.9348e-02, -2.3409e-02,  3.1527e-02, -1.0022e-02,\n",
       "                      -4.9859e-02,  1.7097e-02, -1.1320e-02, -3.3463e-02,  3.8690e-02,\n",
       "                      -1.3417e-02,  5.1747e-02, -1.8919e-02, -5.9902e-03, -1.9544e-02,\n",
       "                       1.0680e-02,  6.9221e-03,  7.0716e-03,  1.3174e-02,  7.4392e-03,\n",
       "                      -2.8518e-02, -2.2731e-02,  8.3109e-02,  1.6202e-02,  6.3554e-02,\n",
       "                      -6.0361e-03, -1.0670e-03, -3.0796e-02, -5.8610e-02,  9.8201e-03,\n",
       "                      -5.1586e-03, -1.4518e-02,  9.4684e-03, -2.2489e-02,  3.9282e-02,\n",
       "                      -1.0210e-02,  8.2050e-03, -3.1120e-02, -1.6071e-02, -1.5244e-02,\n",
       "                      -3.3569e-02,  4.5159e-03, -1.2754e-02,  1.7854e-02, -1.6759e-02,\n",
       "                       1.0063e-02,  2.3056e-02, -2.1792e-02, -3.0049e-02, -1.9480e-02,\n",
       "                      -2.4269e-02, -3.8570e-02,  1.9192e-02,  1.1147e-02,  1.4440e-02,\n",
       "                      -1.3474e-02,  2.2107e-02, -1.4927e-02,  1.1547e-02, -4.6997e-02,\n",
       "                       7.6167e-02,  8.9367e-03, -1.2797e-02,  3.4675e-02, -2.5822e-02,\n",
       "                       9.4820e-03,  3.8152e-02, -1.4008e-03,  2.2138e-03,  3.8086e-02,\n",
       "                       2.7372e-02, -1.8593e-02, -2.0833e-02, -1.1569e-03,  4.4977e-02,\n",
       "                      -1.0372e-02, -7.1596e-03,  4.3219e-03,  3.2602e-02, -1.9086e-02,\n",
       "                      -3.8704e-03, -2.4702e-02,  8.0792e-03,  3.6457e-02, -1.6408e-02,\n",
       "                       6.4451e-02, -2.0553e-02, -4.7925e-03, -4.1339e-02,  4.2574e-02,\n",
       "                       4.0154e-02, -3.0648e-02,  4.7486e-03, -4.8674e-02, -3.7174e-03,\n",
       "                       7.5372e-04,  1.1979e-02,  6.4450e-02,  2.0620e-02,  1.1011e-02,\n",
       "                       6.6325e-02, -3.8013e-02,  2.4567e-02, -2.4458e-02,  1.5904e-02,\n",
       "                      -1.3264e-02,  2.0044e-02,  3.2091e-02,  1.7868e-02, -2.0635e-02,\n",
       "                      -2.6878e-02, -1.6271e-02,  1.3618e-02, -4.5530e-02,  1.3537e-02,\n",
       "                       5.9674e-02, -4.2642e-04,  4.1187e-02, -4.3870e-02,  3.5217e-02,\n",
       "                      -5.5036e-03, -4.2032e-02, -1.7024e-02,  9.0096e-02,  1.0990e-02,\n",
       "                       7.0908e-03,  8.7931e-03, -2.0919e-02,  5.1763e-03, -2.8121e-02,\n",
       "                      -2.4014e-02, -3.9048e-02,  2.6000e-02,  2.9348e-02, -2.1626e-02,\n",
       "                      -4.6632e-02,  3.2504e-03,  1.1490e-02,  8.8762e-03,  5.1383e-02,\n",
       "                       2.0661e-02,  4.3680e-02, -2.2143e-02,  5.8196e-02,  8.8175e-03,\n",
       "                       4.7057e-02, -3.0585e-02, -1.2389e-02, -3.5440e-02,  4.0492e-02,\n",
       "                      -1.3339e-04, -2.0034e-03, -3.3566e-02,  5.6528e-02, -2.1348e-02,\n",
       "                       3.9590e-03, -5.3306e-03, -1.6852e-02, -2.1047e-02,  3.5639e-02,\n",
       "                      -1.6895e-02,  5.6147e-02,  1.2477e-03,  6.1261e-02, -4.2451e-03,\n",
       "                      -4.9502e-02,  4.7818e-02, -1.0344e-02,  7.3455e-02, -1.7588e-02,\n",
       "                      -1.8559e-02,  8.0552e-03,  4.0609e-02,  2.3400e-03,  4.4264e-03,\n",
       "                      -3.2693e-02,  5.8489e-02,  1.8333e-02,  1.1998e-02,  5.4163e-02,\n",
       "                      -1.0971e-02, -3.0371e-02, -4.9338e-03,  1.3687e-02,  4.3225e-02,\n",
       "                       6.7148e-02,  1.4917e-02, -4.0111e-02,  1.2590e-02, -2.9557e-02,\n",
       "                      -1.0344e-02,  3.6250e-02, -3.1385e-02, -3.3276e-02, -9.2465e-03,\n",
       "                      -9.5345e-03,  6.0155e-02, -1.1213e-02, -7.3239e-03, -3.3507e-02,\n",
       "                      -2.6570e-02,  1.8409e-02, -1.3384e-03,  6.8010e-02,  1.1153e-02,\n",
       "                       8.4791e-03, -1.5373e-02, -4.1260e-02,  4.8112e-02, -1.8949e-02,\n",
       "                      -3.6999e-02,  8.9455e-03, -1.7969e-02,  1.4158e-02,  2.3254e-02,\n",
       "                       3.8978e-02, -6.1899e-02, -3.4249e-02,  1.1622e-02, -2.7691e-02,\n",
       "                      -2.0922e-02,  1.1014e-02, -9.5552e-03,  4.1222e-02,  3.9987e-02,\n",
       "                       8.5370e-02,  6.2091e-02, -5.9159e-03, -8.9324e-04,  4.8517e-03,\n",
       "                       1.2310e-02,  2.0460e-02,  5.7480e-02,  1.3781e-02,  4.0997e-03,\n",
       "                      -3.5585e-02, -4.4090e-02, -4.1221e-03, -3.0881e-02,  7.2109e-03,\n",
       "                       1.0301e-03,  2.8474e-03,  6.5431e-02,  3.9754e-02,  5.3380e-02,\n",
       "                       2.9707e-02, -3.9105e-03, -3.1727e-02,  5.8318e-02,  6.6092e-02,\n",
       "                      -3.8355e-02, -3.1163e-02, -1.2734e-03,  1.8741e-02,  1.1619e-02,\n",
       "                      -2.0010e-02, -4.9607e-02,  4.2631e-02, -3.5611e-02,  1.8461e-02,\n",
       "                       6.4621e-03, -6.6002e-04,  2.2937e-02,  4.2202e-02,  3.1475e-02,\n",
       "                       2.7135e-02, -2.8503e-02,  5.4787e-02, -1.3708e-02,  2.2416e-02,\n",
       "                      -1.4539e-02, -5.4458e-02, -3.7459e-02, -3.8315e-02,  4.8708e-02,\n",
       "                       2.8163e-02, -2.5657e-02,  2.6614e-02,  3.0143e-02, -2.5108e-02,\n",
       "                      -2.7303e-02,  2.1417e-02, -8.0630e-04,  3.1859e-02, -1.2845e-02,\n",
       "                      -5.0889e-03,  5.0409e-03, -3.9183e-02,  3.7994e-03,  2.6897e-02,\n",
       "                      -3.1681e-02, -3.6213e-02, -1.0554e-02, -2.5733e-02, -5.2979e-02,\n",
       "                      -1.3864e-02,  2.7330e-03, -4.0177e-02,  4.8409e-02,  2.1774e-02,\n",
       "                       1.4038e-02, -2.5529e-03, -4.3100e-02,  2.9571e-02,  3.8632e-04,\n",
       "                       3.4783e-02,  5.7831e-02, -7.2740e-03, -3.5057e-02,  1.7130e-02,\n",
       "                      -2.4951e-02,  1.8955e-02,  1.7792e-02,  5.3579e-02,  2.4366e-02,\n",
       "                      -9.1021e-03, -6.0911e-03, -3.5898e-02, -3.7800e-03, -2.0098e-03,\n",
       "                       1.9019e-02,  6.2569e-02, -1.3298e-02, -3.7903e-02, -4.7295e-02,\n",
       "                       5.8646e-02,  7.8098e-02, -1.8399e-02, -4.3852e-02,  3.4032e-02,\n",
       "                       4.5148e-02,  6.6232e-02,  2.9183e-02,  2.1263e-02,  5.4021e-03,\n",
       "                       3.0891e-02, -4.4181e-03, -1.8981e-02,  2.4023e-02, -6.0803e-03,\n",
       "                      -8.8602e-03,  7.0116e-03, -1.5746e-02, -1.9727e-02, -3.5271e-02,\n",
       "                      -4.3126e-02, -3.3461e-02,  3.0738e-02,  3.2507e-02,  2.5775e-02,\n",
       "                      -4.4789e-02,  3.5640e-02, -2.6806e-02, -4.4836e-02, -2.1285e-02,\n",
       "                      -5.0809e-02, -1.4578e-02,  1.8299e-02,  5.4772e-02, -1.2985e-02,\n",
       "                       5.3792e-02,  1.5592e-02, -2.9289e-02, -1.5418e-02, -2.0092e-02,\n",
       "                       2.9167e-02, -1.5530e-02, -1.9912e-02, -2.9197e-02,  2.2272e-02,\n",
       "                      -5.3689e-02,  7.8221e-03, -2.0080e-02,  4.1193e-03,  1.0368e-02,\n",
       "                      -2.7054e-02,  1.9599e-02,  3.9978e-04,  3.9081e-02,  5.1501e-02,\n",
       "                      -9.2357e-03, -1.9788e-02, -1.3054e-02, -2.4027e-02,  2.1002e-02,\n",
       "                       3.7997e-02, -5.9758e-03])),\n",
       "             ('line_relu_stack.4.weight',\n",
       "              tensor([[ 0.0352,  0.0051,  0.0277,  ..., -0.0012,  0.0432, -0.0202],\n",
       "                      [ 0.0358, -0.0049, -0.0106,  ...,  0.0324, -0.0363, -0.0345],\n",
       "                      [ 0.0134, -0.0727,  0.0264,  ..., -0.0267, -0.0261,  0.0166],\n",
       "                      ...,\n",
       "                      [ 0.0936, -0.0199,  0.1052,  ..., -0.0427,  0.0066, -0.0308],\n",
       "                      [ 0.1092, -0.0319, -0.0249,  ..., -0.0193, -0.0371, -0.0043],\n",
       "                      [-0.0202,  0.0273, -0.0081,  ...,  0.0052,  0.0388, -0.0089]])),\n",
       "             ('line_relu_stack.4.bias',\n",
       "              tensor([ 0.0004,  0.0286,  0.0285,  0.0197, -0.0952,  0.4098,  0.1280,  0.0632,\n",
       "                      -0.0388, -0.1002]))])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load = NeuralNetwork()\n",
    "model_load.load_state_dict(torch.load('model_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (line_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (5): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = torch.load('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx as onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
