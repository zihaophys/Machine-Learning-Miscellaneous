# Machine Learning Miscellaneous


*ESL on your left,*
*Python on your right,*
*Empirical Bayes on your mind.*



- [Microsorft: ml-for-beginners](MS-ML-Basics)

- [Cross Validation demo](cross_validation.ipynb)

- [Introduction to Emprical Bayes: Galton Family](GaltonFamily.ipynb)

- [James-Stein estimator for two groups](JSE/JSE_Cov.ipynb)

- [Introduction to Linear Mixed Model](LMM/LMM_intro_py.ipynb)

- [EM application: Linear Mixed Model with three variance component](EM/three-variance-lmm.ipynb)

- [EM application: Regression of Dirichlet Multinomial Model](EM/DMM.ipynb)

- [EM application: A causal inference model](EM/CausalInference.ipynb)

- [Comparison of EM and Mean-field EM on Linear Mixed Model](VI/linearModel.ipynb)

- [Comparison of EM and James-Stein estiamtor](EM/Comparison_EM_JSE.ipynb)

- [James-Stein estimator is Ridge](JSE/JSE_Ridge.ipynb)

- [Gradient flow is Ridge](EQ/Gradient_Flow.ipynb)

- [Ridge + Ridge is Lasso](EQ/doubleRidgevsLasso.ipynb)

- [Boosting Regression is Lasso](EQ/linRegFS_vs_lasso.ipynb)

- [Random Forest is Lasso](GB/RF.ipynb)

- [Introduction to Ada-Boosting](GB/adaBoosting.ipynb)

- [Introduction to Gradient Boosting](GB/GradientBoosting.ipynb)

- [Introduction to XG-Boost](GB/XGBoost.ipynb)

- [Comparison of  Ada-Boosting, SAMME and Gradient Boosting](GB/multiClass.ipynb)
